{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Copernicus Query and Download\n",
                "\n",
                "(c) 2024 Panopterra UG (haftungsbeschraenkt)\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load packages and modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "import requests\n",
                "import warnings\n",
                "from datetime import datetime\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import geopandas as gpd\n",
                "import shapely.wkt\n",
                "from shapely import Point, Polygon, MultiPolygon, make_valid\n",
                "from shapely.ops import unary_union\n",
                "\n",
                "from ._constants import COLLECTIONS_SUPPORTING_CLOUD_COVER, COLLECTION_PRODUCT_TYPE_MATCHES\n",
                "from .response import get_checksums, get_cloud_cover, get_product_type, determine_group_tile_identifier\n",
                "from .query import reduce_wkt_coordinate_precision, convert_special_characters, \\\n",
                "interpret_collection_name, interpret_product_type\n",
                "from .vector import reproject_geometry"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Internal functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "warnings.simplefilter(action='ignore', category=UserWarning)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Custom Errors"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CopernicusQueryConstructorError(Exception):\n",
                "    \"\"\"\n",
                "    A custom error class for query check fails.\n",
                "    \"\"\"\n",
                "\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CopernicusQueryAttributeError(Exception):\n",
                "    \"\"\"\n",
                "    A custom error class for cases where an attribute filter is set for a \n",
                "    pre-defined attribute.\n",
                "    \"\"\"\n",
                "\n",
                "    pass"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Query"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### QueryConstructor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class QueryConstructor:\n",
                "    \"\"\"\n",
                "    Allows easy step-by-step construction of an ODATA query to Copernicus DataSpace.\n",
                "    See Notes for details on behavior.\n",
                "    \n",
                "    Parameters\n",
                "    ----------\n",
                "    interactive : bool; default=False\n",
                "        If True, enables automatic 'testing' of the query. This means that whenever\n",
                "        a new filter is added, the query is sent to the API and the number of products \n",
                "        in the current query is reported in logs.\n",
                "        NOTE: the testing is only run when at least three filter criteria have been\n",
                "        added to avoid excessive query runs for generic filters like 'Sentinel-2'\n",
                "        resulting in 1000s of products.\n",
                "    request_timeout : int; default=60\n",
                "        The maximum time to wait for a response from the API for any request/download\n",
                "        sent (in seconds).\n",
                "    max_retries : int; default=3\n",
                "        The number of retries in case of any issues during API requests.\n",
                "    decimals : int; default=6\n",
                "        The number of decimals to use in AOI coordinates (i.e. coordinate precision).\n",
                "        NOTE: decimal places are cut off, not rounded.\n",
                "\n",
                "    Attributes\n",
                "    ----------\n",
                "    _n_filters : int\n",
                "        The number of filters applied so far (to avoid checking too unspecific\n",
                "        queries; see interactive parameter description above).\n",
                "    _query_parts : dict\n",
                "        Contains the individual filter settings parts of the query as individual\n",
                "        strings.\n",
                "    _query_settings : dict\n",
                "        Contains the individual filter settings provided by the user.\n",
                "    interactive : bool\n",
                "        See __init__.\n",
                "    max_retries : int\n",
                "        See __init__.\n",
                "    request_timeout : int\n",
                "        See __init__.\n",
                "\n",
                "    Notes\n",
                "    -----\n",
                "    Way of operation:\n",
                "    Each method adds a different type of filter to the query. If the same method\n",
                "    is called multiple times, it overwrites the previous settings. The only exception\n",
                "    to this is the add_attribute_filter method where each call will add an additional\n",
                "    filter to the list.\n",
                "    Due to the way the ODATA API works, all filters are combined via boolean AND.\n",
                "\n",
                "    Limitation:\n",
                "    This class is purely intended for constructing the main filter part of the\n",
                "    query. Options relating to queries for specific products (by name/ID) or\n",
                "    selecting query results (like top/skip etc.) are handled separately as needed\n",
                "    in other functions/classes.\n",
                "\n",
                "    For details on the OpenData API, please refer to the documentation:\n",
                "    https://documentation.dataspace.copernicus.eu/APIs/OData.html\n",
                "    \"\"\"\n",
                "\n",
                "    def __init__(self, \n",
                "                 interactive : bool = False,\n",
                "                 request_timeout : int = 60,\n",
                "                 max_retries : int = 3,\n",
                "                 decimals : int = 6) -> None:\n",
                "\n",
                "        self.interactive = interactive\n",
                "        self.request_timeout = request_timeout\n",
                "        self.max_retries = max_retries\n",
                "        self.decimals = decimals\n",
                "        self._n_filters = 0\n",
                "        self._products = None\n",
                "        self._query_parts = {}\n",
                "        self._query_settings = {'aoi': None,\n",
                "                                'collection': None,\n",
                "                                'product_type': None,\n",
                "                                'publication_date': None,\n",
                "                                'sensing_start_date': None,\n",
                "                                'sensing_end_date': None,\n",
                "                                'cloud_cover': None,\n",
                "                                'attributes': None}\n",
                "    \n",
                "    ### INTERNAL METHODS\n",
                "\n",
                "    def _create_products_geodataframe(self, \n",
                "                                      products : list[dict]) -> gpd.GeoDataFrame:\n",
                "        \"\"\"\n",
                "        Creates a GeoDataFrame from products received from API, does some preparations\n",
                "        and creates a few additional (unified) columns for later use.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        products : list of dic\n",
                "            The products as returned by the API.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        gpd.GeoDataFrame\n",
                "            Contains all metadata from products, incl. additional columns produced.\n",
                "        \"\"\"\n",
                "\n",
                "        # create a simple pd.DataFrame from products list\n",
                "        df = pd.DataFrame(products)\n",
                "\n",
                "        # extract/unify some information from existing columns\n",
                "        df['file_name'] = df['Name']\n",
                "        df['file_size'] = df['ContentLength'].apply(lambda x: x / 1024 / 1024)\n",
                "        df['group_tile_id'] = df['Name'].apply(determine_group_tile_identifier)\n",
                "        df['cloud_cover'] = df['Attributes'].apply(get_cloud_cover)\n",
                "        df['product_type'] = df['Attributes'].apply(get_product_type)\n",
                "        df[['checksum_md5', 'checksum_blake3']] = list(df['Checksum'].apply(get_checksums))\n",
                "        df['download_url'] = df['Id'].apply(lambda x: f\"https://download.dataspace.copernicus.eu/odata/v1/Products({x})/$value\")\n",
                "        df['geometry'] = df['Footprint'].apply(lambda x: shapely.wkt.loads(x.split(';')[-1].strip(\"'\\\"\")).buffer(0))\n",
                "\n",
                "        # convert date strings to datetime objects; omitting milliseconds for compatibility\n",
                "        df['publication_date'] = df['PublicationDate'].apply(lambda x: datetime.strptime(x.split('.')[0], '%Y-%m-%dT%H:%M:%S'))\n",
                "        df['sensing_start_date'] = df['ContentDate'].apply(lambda x: datetime.strptime(x['Start'].split('.')[0], '%Y-%m-%dT%H:%M:%S'))\n",
                "        df['sensing_end_date'] = df['ContentDate'].apply(lambda x: datetime.strptime(x['End'].split('.')[0], '%Y-%m-%dT%H:%M:%S'))\n",
                "                                             \n",
                "        # convert to gpd.GeoDataFrame in WGS84\n",
                "        gdf = gpd.GeoDataFrame(df, crs='epsg:4326')\n",
                "\n",
                "        # additional geometry columns; calculating footprint_size and aoi_coverage\n",
                "        # in web mercator projection (3857)\n",
                "        gdf_web_mercator = gdf.to_crs('epsg:3857')\n",
                "        gdf['centroid'] = gdf['geometry'].centroid\n",
                "        gdf['footprint_size'] = gdf_web_mercator['geometry'].area / 1e6\n",
                "\n",
                "        # AOI coverage\n",
                "        if self.query_settings['aoi'] is not None:\n",
                "            aoi = reproject_geometry(self.query_settings['aoi'], 4326, 3857)\n",
                "            gdf['aoi_coverage'] = gdf_web_mercator.intersection(aoi).area / aoi.area\n",
                "        else:\n",
                "            gdf['aoi_coverage'] = 1.\n",
                "        \n",
                "        return gdf\n",
                "    \n",
                "\n",
                "    ### PROPERTIES\n",
                "    \n",
                "    @property\n",
                "    def aoi_coverage(self):\n",
                "        \"\"\"\n",
                "        Returns the total AOI coverage of all products in the current query as\n",
                "        a fraction. If no products are found or no AOI was set, returns 0.\n",
                "        \"\"\"\n",
                "        \n",
                "        if self._products is None or self.query_settings['aoi'] is None:\n",
                "            print('No products found or no AOI set. AOI coverage of 0.')\n",
                "            return 0.\n",
                "        elif len(self._products) == 0:\n",
                "            print('No products found. AOI coverage of 0.')\n",
                "            return 0.\n",
                "        else:\n",
                "            if self.query_settings['aoi'].area == 0:\n",
                "                return 1.\n",
                "            else:\n",
                "                return np.round(self._products.unary_union.intersection(self.query_settings['aoi']).area / self.query_settings['aoi'].area, 5)\n",
                "    \n",
                "    @property\n",
                "    def api_response(self):\n",
                "        \"\"\"\n",
                "        Returns the API response (JSON) of the latest call of send_query().\n",
                "        \"\"\"\n",
                "\n",
                "        return self._latest_result\n",
                "        \n",
                "    @property\n",
                "    def products(self):\n",
                "        \"\"\"\n",
                "        Returns the current products GeoDataFrame. If not available, will call\n",
                "        send_query() and update internal attributes.\n",
                "        In other words: always returns the current version of the products table\n",
                "        and ensures the latest results are stored.\n",
                "        \"\"\"\n",
                "\n",
                "        if self._products is None:\n",
                "            products, result = self.send_query()\n",
                "            products = products\n",
                "            self._latest_result = result\n",
                "            self._products = products\n",
                "            return products.sort_values('Name').reset_index(drop=True)\n",
                "        else:\n",
                "            return self._products.sort_values('Name').reset_index(drop=True)\n",
                "    \n",
                "    @property\n",
                "    def query(self) -> str:\n",
                "        \"\"\"\n",
                "        Returns the current version of the query.\n",
                "        \"\"\"\n",
                "\n",
                "        query = 'https://catalogue.dataspace.copernicus.eu/odata/v1/Products?'\n",
                "\n",
                "        # add filters\n",
                "        query += '$filter='\n",
                "        other_filters = [self._query_parts[k] for k in self._query_parts.keys() if k != 'attributes']\n",
                "        query += ' and '.join(other_filters)\n",
                "\n",
                "        # handle attribute filters separately\n",
                "        if 'attributes' in self._query_parts.keys():\n",
                "            attributes_filter = ' and '.join(self._query_parts['attributes'])\n",
                "            query += f' and {attributes_filter}'\n",
                "\n",
                "        return query\n",
                "    \n",
                "    @property\n",
                "    def query_settings(self) -> dict:\n",
                "        \"\"\"\n",
                "        Returns the current query settings.\n",
                "        \"\"\"\n",
                "\n",
                "        return self._query_settings\n",
                "    \n",
                "\n",
                "    ### EXTERNAL METHODS\n",
                "\n",
                "    def add_aoi_filter(self, \n",
                "                       aoi : Point|Polygon|MultiPolygon|list[Point|Polygon|MultiPolygon],\n",
                "                       decimals : int = None) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a specific AOI (point of polygon).\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        aoi : shapely.Point/shapely.Polygon/shapely.MultiPolygon or list of shapely.Point/shapely.Polygon/shapely.MultiPolygon\n",
                "            The area of interest. Must be in WGS84.\n",
                "            NOTE: any input that is not a single Point or Polygon will be converted\n",
                "            to a (Multi)Polygon via unary_union.\n",
                "        decimals : int; default=None\n",
                "            The number of decimals to use in AOI coordinates (i.e. coordinate precision).\n",
                "            If None, uses the number of decimals provided during initialization\n",
                "            (default: 6).\n",
                "            NOTE: decimal places are cut off, not rounded.\n",
                "\n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        # convert other geometry types or lists of geometries to Polygon/MultiPolygon\n",
                "        if not isinstance(aoi, Point) and not isinstance(aoi, Polygon):\n",
                "            aoi = unary_union(aoi)\n",
                "        \n",
                "        # make invalid geometries valid\n",
                "        if not aoi.is_valid:\n",
                "            aoi = make_valid(aoi)\n",
                "\n",
                "        # determine decimal precision\n",
                "        if decimals is None:\n",
                "            decimals = self.decimals\n",
                "\n",
                "        wkt_str = reduce_wkt_coordinate_precision(aoi.wkt, decimals=self.decimals)\n",
                "        if len(wkt_str) > 2000:\n",
                "            print(f'AOI WKT string is very long ({len(wkt_str)}). Consider simplifying the AOI polygon to reduce risk of exceeding query string limit.')\n",
                "        print(f'Adding AOI filter: {wkt_str}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'aoi' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['aoi'] = f\"ODATA.CSC.Intersects(area=geography'SRID=4326;{wkt_str}')\"\n",
                "        self._query_settings['aoi'] = aoi\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_attribute_filter(self, \n",
                "                             name : str,\n",
                "                             operator : str,\n",
                "                             value : str|int|float,\n",
                "                             attribute_type : str) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a specific attribute.\n",
                "        For further details, please refer to the OpenData API documentation:\n",
                "        https://documentation.dataspace.copernicus.eu/APIs/OData.html#query-by-attributes\n",
                "\n",
                "        NOTE: this method supports filtering for any available attribute, except\n",
                "        cloudCover and productType (use corresponding methods instead).\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        name : str\n",
                "            Name of the attribute.\n",
                "        operator : str\n",
                "            The boolean operator to use for the query. The API supports the following\n",
                "            operators (depending on the attribute type, see API documentation):\n",
                "            eq: equal;\n",
                "            lt: lower than;\n",
                "            le: lower than or equal;\n",
                "            gt: greater than;\n",
                "            ge: greater than or equal.\n",
                "        value : str or int or float\n",
                "            The value expected for the operator (data type of this parameter should\n",
                "            be in accordance to the attribute type).\n",
                "        attribute_type : str\n",
                "            Type of attribute. Options:\n",
                "            string: StringAttribute;\n",
                "            integer: IntegerAttribute;\n",
                "            double: DoubleAttribute;\n",
                "            datetimeoffset: DateTimeOffsetAttribute.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        if name == 'cloudCover':\n",
                "            raise CopernicusQueryAttributeError(f\"To filter by cloud cover, please use the add_cloud_cover_filter method instead.\")\n",
                "        elif name == 'productType':\n",
                "            raise CopernicusQueryAttributeError(f\"To filter by product type, please use the add_product_type_filter method instead.\")\n",
                "        \n",
                "        # convert special characters in attributes before creating query\n",
                "        name = convert_special_characters(name)\n",
                "        value = convert_special_characters(value)\n",
                "\n",
                "        print(f'Adding attribute filter: {name} {operator} {value} ({attribute_type})')\n",
                "        if 'attributes' not in self._query_parts.keys():\n",
                "            self._query_parts['attributes'] = []\n",
                "            self._query_settings['attributes'] = []\n",
                "\n",
                "        self._query_parts['attributes'].append(f\"Attributes/OData.CSC.{attribute_type.capitalize()}Attribute/any(att:att/Name eq '{name}' and att/OData.CSC.{attribute_type.capitalize()}Attribute/Value {operator} '{value}')\")\n",
                "        self._query_settings['attributes'].append((name, operator, value, attribute_type))\n",
                "        self._n_filters += 1\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_cloud_cover_filter(self,\n",
                "                               ccover : int|float|tuple[int]|tuple[float]) -> None:\n",
                "        \"\"\"\n",
                "        Filters by cloud cover.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        ccover : int/float or tuple of int/float\n",
                "            If a single int/float is provided, will be interpreted as the maximum\n",
                "            allowed cloud cover. If a tuple of two ints/floats is provided, will\n",
                "            be interpreted as (minimum, maximum).\n",
                "            NOTE: values in percentage between 0 and 100. Maximum accuracy of \n",
                "            query is 2 decimal places (e.g., 10.35764 would be queried as 10.35).\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        # verify compatibility with collection\n",
                "        if self._query_settings['collection'] is not None:\n",
                "            if self._query_settings['collection'] not in COLLECTIONS_SUPPORTING_CLOUD_COVER:\n",
                "                raise CopernicusQueryConstructorError(f\"Collection of name '{self._query_settings['collection'].upper()}' does not support cloud cover filter.\")\n",
                "\n",
                "        if isinstance(ccover, float) or isinstance(ccover, int):\n",
                "            ccover_max = ccover\n",
                "            ccover_min = 0\n",
                "        else:\n",
                "            ccover_min, ccover_max = ccover\n",
                "\n",
                "        print(f'Adding cloud cover filter: {ccover_min} to {ccover_max}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'cloud_cover' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['cloud_cover'] = f\"Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value ge {ccover_min:.2f}) and Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value le {ccover_max:.2f})\"\n",
                "        self._query_settings['cloud_cover'] = ccover\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_collection_filter(self, \n",
                "                              collection : str) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a specific collection.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        collection : str\n",
                "            The collection to query.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        collection_name = interpret_collection_name(collection)\n",
                "        if collection_name is None:\n",
                "            raise CopernicusQueryAttributeError(f\"Collection name '{collection}' not recognized.\")\n",
                "        \n",
                "        # check if collection supports previously defined product type\n",
                "        product_type_name = self.query_settings['product_type']\n",
                "        if product_type_name is not None:\n",
                "            # if value in dictionary is None, indicates that there is no specific\n",
                "            # set of allowed product type names\n",
                "            if COLLECTION_PRODUCT_TYPE_MATCHES[collection_name] is not None:\n",
                "                if product_type_name not in COLLECTION_PRODUCT_TYPE_MATCHES[collection_name]:\n",
                "                    raise CopernicusQueryAttributeError(f\"Collection '{collection_name}' does not support product type '{product_type_name}'. Valid options: {', '.join(COLLECTION_PRODUCT_TYPE_MATCHES[collection_name])}\")\n",
                "\n",
                "        # verify compatibility with collection\n",
                "        if self._query_settings['cloud_cover'] is not None:\n",
                "            if collection_name not in COLLECTIONS_SUPPORTING_CLOUD_COVER:\n",
                "                raise CopernicusQueryConstructorError(f\"Collection of name '{collection_name}' does not support cloud cover filter.\")\n",
                "\n",
                "        print(f'Adding collection filter: {collection_name}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'collection' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['collection'] = f\"Collection/Name eq '{collection_name}'\"\n",
                "        self._query_settings['collection'] = collection_name\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_product_type_filter(self, \n",
                "                                product_type : str) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a specific product type.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        product_type : str\n",
                "            The product type.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        product_type_name = interpret_product_type(product_type)\n",
                "        if product_type_name is None:\n",
                "            raise CopernicusQueryAttributeError(f\"Product type name '{product_type}' not recognized.\")\n",
                "        \n",
                "        # check if provided product type is valid for the given collection\n",
                "        collection_name = self.query_settings['collection']\n",
                "        if collection_name is not None:\n",
                "            # if value in dictionary is None, indicates that there is no specific\n",
                "            # set of allowed product type names\n",
                "            if COLLECTION_PRODUCT_TYPE_MATCHES[collection_name] is not None:\n",
                "                if product_type_name not in COLLECTION_PRODUCT_TYPE_MATCHES[collection_name]:\n",
                "                    raise CopernicusQueryAttributeError(f\"Product type '{product_type_name}' not available for collection '{collection_name}'. Valid options: {', '.join(COLLECTION_PRODUCT_TYPE_MATCHES[collection_name])}\")\n",
                "\n",
                "        print(f'Adding product type filter: {product_type_name}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'product_type' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['product_type'] = f\"Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq '{product_type_name}')\"\n",
                "        self._query_settings['product_type'] = product_type_name\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_publication_date_filter(self, \n",
                "                                    start : str|datetime, \n",
                "                                    end : str|datetime) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a publication date range.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        start : str or datetime.datetime\n",
                "            The start date as either a string of format 'YYYY-MM-DDThh:mm:ss.000Z'\n",
                "            or a datetime object.\n",
                "        end : str or datetime.datetime\n",
                "            The end date as either a string of format 'YYYY-MM-DDThh:mm:ss.000Z'\n",
                "            or a datetime object.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        if isinstance(start, datetime):\n",
                "            start_str = datetime.strftime(start, '%Y-%m-%dT%H:%M:%S.000Z')\n",
                "        else:\n",
                "            start_str = start\n",
                "        if isinstance(end, datetime):\n",
                "            end_str = datetime.strftime(end, '%Y-%m-%dT%H:%M:%S.000Z')\n",
                "        else:\n",
                "            end_str = end\n",
                "\n",
                "        print(f'Adding publication date filter: {start_str} to {end_str}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'publication_date' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['publication_date'] = f'PublicationDate ge {start_str} and PublicationDate le {end_str}'\n",
                "        self._query_settings['publication_date'] = (start, end)\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_sensing_end_date_filter(self,\n",
                "                                    start : str|datetime, \n",
                "                                    end : str|datetime) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a sensing end date range.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        start : str or datetime.datetime\n",
                "            The start date as either a string of format 'YYYY-MM-DDThh:mm:ss.000Z'\n",
                "            or a datetime object.\n",
                "        end : str or datetime.datetime\n",
                "            The end date as either a string of format 'YYYY-MM-DDThh:mm:ss.000Z'\n",
                "            or a datetime object.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        if isinstance(start, datetime):\n",
                "            start_str = datetime.strftime(start, '%Y-%m-%dT%H:%M:%S.000Z')\n",
                "        else:\n",
                "            start_str = start\n",
                "        if isinstance(end, datetime):\n",
                "            end_str = datetime.strftime(end, '%Y-%m-%dT%H:%M:%S.000Z')\n",
                "        else:\n",
                "            end_str = end\n",
                "\n",
                "        print(f'Adding sensing end date filter: {start_str} to {end_str}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'sensing_end_date' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['sensing_end_date'] = f'ContentDate/End ge {start_str} and ContentDate/End le {end_str}'\n",
                "        self._query_settings['sensing_end_date'] = (start, end)\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "\n",
                "    def add_sensing_start_date_filter(self,\n",
                "                                      start : str|datetime, \n",
                "                                      end : str|datetime) -> None:\n",
                "        \"\"\"\n",
                "        Filters for a sensing start date range.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        start : str or datetime.datetime\n",
                "            The start date as either a string of format 'YYYY-MM-DDThh:mm:ss.000Z'\n",
                "            or a datetime object.\n",
                "        end : str or datetime.datetime\n",
                "            The end date as either a string of format 'YYYY-MM-DDThh:mm:ss.000Z'\n",
                "            or a datetime object.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        None\n",
                "        \"\"\"\n",
                "\n",
                "        if isinstance(start, datetime):\n",
                "            start_str = datetime.strftime(start, '%Y-%m-%dT%H:%M:%S.000Z')\n",
                "        else:\n",
                "            start_str = start\n",
                "        if isinstance(end, datetime):\n",
                "            end_str = datetime.strftime(end, '%Y-%m-%dT%H:%M:%S.000Z')\n",
                "        else:\n",
                "            end_str = end\n",
                "\n",
                "        print(f'Adding sensing start date filter: {start_str} to {end_str}')\n",
                "        # only increment filter count if the same filter has not already been set before\n",
                "        if 'sensing_start_date' not in self._query_parts.keys():\n",
                "            self._n_filters += 1\n",
                "        self._query_parts['sensing_start_date'] = f'ContentDate/Start ge {start_str} and ContentDate/Start le {end_str}'\n",
                "        self._query_settings['sensing_start_date'] = (start, end)\n",
                "\n",
                "        if self.interactive and self._n_filters >= 3:\n",
                "            _ = self.check_query()\n",
                "    \n",
                "    def check_query(self) -> int:\n",
                "        \"\"\"\n",
                "        Checks the query as it is currently defined by sending the current version\n",
                "        of the query to the API, not retrieving all results in detail. For that,\n",
                "        please use send_query() instead.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        None\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        int\n",
                "            The number of products in the query.\n",
                "        \"\"\"\n",
                "\n",
                "        result = requests.get(self.query+'&$count=True&$top=1').json()\n",
                "        if '@odata.count' not in result.keys():\n",
                "            raise CopernicusQueryConstructorError(f'Error or empty query result: {result}')\n",
                "        n_products = result['@odata.count']\n",
                "        print(f'Current query contains {n_products} products.')\n",
                "        return n_products\n",
                "    \n",
                "    def create_copy(self):\n",
                "        \"\"\"\n",
                "        Creates a copy of itself (new instance with same settings).\n",
                "        Primarily intended when used in other classes that may modify settings in\n",
                "        the instance.\n",
                "        \n",
                "        Parameters\n",
                "        ----------\n",
                "        None\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        QueryConstructor\n",
                "            New instance (copy).\n",
                "        \"\"\"\n",
                "\n",
                "        new_instance = QueryConstructor(self.interactive)\n",
                "        new_instance._n_filters = self._n_filters\n",
                "        new_instance._query_parts = self._query_parts.copy()\n",
                "        new_instance._query_settings = self._query_settings.copy()\n",
                "        return new_instance\n",
                "    \n",
                "    def query_by_name(self, \n",
                "                      product_names : list[str]) -> tuple[gpd.GeoDataFrame,dict]:\n",
                "        \"\"\"\n",
                "        Retrieves a list of specific products by name.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        product_names : list of str\n",
                "            Contains the names of products to retrieve from Catalog API (incl.\n",
                "            extensions such as '.SAFE').\n",
                "            NOTE: ideally, the list should not be longer than a few dozen items.\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        gpd.GeoDataFrame\n",
                "            Contains information about all products in the query.\n",
                "        dict\n",
                "            The raw result as returned by the API.\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        This methods uses the GET command for retrieving individual items from\n",
                "        the Catalog API. The best practice would be to use a POST command\n",
                "        instead (as recommended in the API documentation), however, that option\n",
                "        does not seem to allow to expand Assets and Attributes resulting in issues\n",
                "        with subsequent steps.\n",
                "        As a result, long lists of product names can lead to large numbers of \n",
                "        API calls.\n",
                "        \"\"\"\n",
                "        \n",
                "        # send the query, retrieve results\n",
                "        products = []\n",
                "        for name in product_names:\n",
                "            result = requests.get(f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?&$count=True&$expand=Attributes&$expand=Assets&$filter=Name eq '{name}'\", timeout=self.request_timeout).json()\n",
                "            if '@odata.count' in result.keys():\n",
                "                products.extend(result['value'])\n",
                "\n",
                "        # if the full result contains any products, prepare results and update\n",
                "        # internal attribautes\n",
                "        if len(products) > 0:\n",
                "            products = self._create_products_geodataframe(products)\n",
                "            total_file_size = np.sum(products['file_size'].values) / 1024\n",
                "            percentage_online = np.sum(products['Online']) / len(products)\n",
                "            print(f'Retrieved {len(products)} products ({total_file_size:.2f} GB, {percentage_online*100:.2f}% online).')\n",
                "            # update internal attributes with current result\n",
                "            self._products = products\n",
                "            self._latest_result = result\n",
                "\n",
                "            return products, result\n",
                "        else:\n",
                "            raise CopernicusQueryConstructorError('No products matching query.')\n",
                "\n",
                "    def send_query(self,\n",
                "                   skip : int = 0,\n",
                "                   n_entries : int = 1000,\n",
                "                   orderby : str = None) -> tuple[gpd.GeoDataFrame,dict]:\n",
                "        \"\"\"\n",
                "        Sends the query in its current form to the API. Stores current results in\n",
                "        attributes.\n",
                "\n",
                "        Parameters\n",
                "        ----------\n",
                "        skip : int; default=0\n",
                "            Number of items to skip in query, e.g. to only consider later\n",
                "            results.\n",
                "        n_entries : int; default=1000\n",
                "            Number of items to retrieve in a single API call.\n",
                "        orderby : str; default=None\n",
                "            The field to order results. For details and limitations, please refer \n",
                "            to API documentation:\n",
                "            https://documentation.dataspace.copernicus.eu/APIs/OData.html#orderby-option\n",
                "        \n",
                "        Returns\n",
                "        -------\n",
                "        gpd.GeoDataFrame\n",
                "            Contains information about all products in the query.\n",
                "        dict\n",
                "            The raw result as returned by the API.\n",
                "\n",
                "        Notes\n",
                "        -----\n",
                "        Handling of large product lists:\n",
                "        Each query returns the number of products in the entire query result \n",
                "        ('count=True') but only n_entries are returned with each request. If n_entries\n",
                "        is smaller than the total number of products in the query, this method will\n",
                "        auromatically run further API calls to retrieve all products.\n",
                "\n",
                "        Updates to internal attributes:\n",
                "        Each time this method is called, it updates the internal _latest_result\n",
                "        attribute based on the results obtained from the API call. Only exception: \n",
                "        if the product list is empty, the result is not stored.\n",
                "        \"\"\"\n",
                "        \n",
                "        print('Sending query.')\n",
                "        \n",
                "        # get query and add additional parameters as required\n",
                "        query = self.query\n",
                "        if skip is not None:\n",
                "            query += f'&$skip={skip}'\n",
                "        if n_entries is not None:\n",
                "            query += f'&$top={n_entries}'\n",
                "        if orderby is not None:\n",
                "            query += f'&$orderby={orderby[0]} {orderby[1]}'\n",
                "\n",
                "        # send the query, retrieve results; attempt retries if API is unresponsive\n",
                "        for _ in range(self.max_retries):\n",
                "            try:\n",
                "                result = requests.get(query+'&$count=True&$expand=Attributes&$expand=Assets&$expand=Locations', timeout=self.request_timeout).json()\n",
                "                if '@odata.count' not in result.keys():\n",
                "                    if 'Invalid value' in result:\n",
                "                        raise CopernicusQueryConstructorError(f'Invalid value provided to result: {result}')\n",
                "                    else:\n",
                "                        raise CopernicusQueryConstructorError(f'Error or empty query result: {result}')\n",
                "                products = result['value']\n",
                "                break\n",
                "            except Exception as e:\n",
                "                print(f'Request failed (waiting for retry). -> {type(e).__name__}: {e}')\n",
                "                time.sleep(5)\n",
                "\n",
                "        # run additional API calls to obtain all pages of results if number of\n",
                "        # products is larger than n_entries\n",
                "        while '@odata.nextLink' in result.keys():\n",
                "            query = result['@odata.nextLink']\n",
                "            query = query.split('&$count')[0]\n",
                "            result = requests.get(query, timeout=self.request_timeout).json()\n",
                "            products.extend(result['value'])\n",
                "        \n",
                "        # if the full result contains any products, prepare results and update\n",
                "        # internal attribautes\n",
                "        if len(products) > 0:\n",
                "            products = self._create_products_geodataframe(products)\n",
                "            total_file_size = np.sum(products['file_size'].values) / 1024\n",
                "            percentage_online = np.sum(products['Online']) / len(products)\n",
                "            print(f'Retrieved {len(products)} products ({total_file_size:.2f} GB, {percentage_online*100:.2f}% online).')\n",
                "            # update internal attributes with current result\n",
                "            self._products = products\n",
                "            self._latest_result = result\n",
                "\n",
                "            return products, result\n",
                "        else:\n",
                "            raise CopernicusQueryConstructorError('No products matching query.')"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "efdd46ba2b7f8a252690b16440602db3784b64c8c7d7cfae3f3fd228441ea834"
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
